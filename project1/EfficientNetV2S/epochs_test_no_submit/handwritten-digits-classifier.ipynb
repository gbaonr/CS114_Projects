{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4408314c",
   "metadata": {
    "papermill": {
     "duration": 0.005171,
     "end_time": "2025-06-09T17:09:22.309708",
     "exception": false,
     "start_time": "2025-06-09T17:09:22.304537",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Data preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ec89619",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T17:09:22.319704Z",
     "iopub.status.busy": "2025-06-09T17:09:22.319495Z",
     "iopub.status.idle": "2025-06-09T17:09:27.069107Z",
     "shell.execute_reply": "2025-06-09T17:09:27.068395Z"
    },
    "papermill": {
     "duration": 4.755875,
     "end_time": "2025-06-09T17:09:27.070564",
     "exception": false,
     "start_time": "2025-06-09T17:09:22.314689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install pyheif pillow -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f53f8e78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T17:09:27.080374Z",
     "iopub.status.busy": "2025-06-09T17:09:27.080112Z",
     "iopub.status.idle": "2025-06-09T17:09:37.369123Z",
     "shell.execute_reply": "2025-06-09T17:09:37.368525Z"
    },
    "papermill": {
     "duration": 10.295477,
     "end_time": "2025-06-09T17:09:37.370545",
     "exception": false,
     "start_time": "2025-06-09T17:09:27.075068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# transform data\n",
    "# transform data\n",
    "import torchvision.transforms.v2 as T\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from IPython.display import display\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.io import read_image\n",
    "from torchvision.io import decode_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9979b7bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T17:09:37.380462Z",
     "iopub.status.busy": "2025-06-09T17:09:37.380129Z",
     "iopub.status.idle": "2025-06-09T17:09:38.531597Z",
     "shell.execute_reply": "2025-06-09T17:09:38.530735Z"
    },
    "papermill": {
     "duration": 1.157742,
     "end_time": "2025-06-09T17:09:38.532853",
     "exception": false,
     "start_time": "2025-06-09T17:09:37.375111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True\n",
      "train: 5917, val: 1354\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "data_dir = \"/kaggle/input/handwritten-tl/digits_data\"\n",
    "train_dir = os.path.join(data_dir, \"train\")\n",
    "val_dir = os.path.join(data_dir, \"val\")\n",
    "print(os.path.exists(train_dir), os.path.exists(val_dir))\n",
    "\n",
    "# origin_train_list = [img for img in glob.glob(train_dir + \"/*/*\") if os.path.isfile(img)]\n",
    "# origin_val_list = [img for img in glob.glob(val_dir + \"/*/*\") if os.path.isfile(img)]\n",
    "origin_train_list = glob.glob(train_dir + \"/*/*\")\n",
    "origin_val_list = glob.glob(val_dir + \"/*/*\")\n",
    "train_list = origin_train_list[:]\n",
    "val_list = origin_val_list[:]\n",
    "random.shuffle(train_list)\n",
    "random.shuffle(val_list)\n",
    "print(f\"train: {len(train_list)}, val: {len(val_list)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a48cf8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T17:09:38.542827Z",
     "iopub.status.busy": "2025-06-09T17:09:38.542330Z",
     "iopub.status.idle": "2025-06-09T17:09:38.549525Z",
     "shell.execute_reply": "2025-06-09T17:09:38.548874Z"
    },
    "papermill": {
     "duration": 0.013136,
     "end_time": "2025-06-09T17:09:38.550570",
     "exception": false,
     "start_time": "2025-06-09T17:09:38.537434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function to process data: gray_100x100_norm\n",
    "# DO NOT CHANGE IN THE SAME DATA VERSION\n",
    "transform = transforms.v2.Compose([\n",
    "    T.ToImage(),\n",
    "    T.Grayscale(num_output_channels=1),\n",
    "    T.Resize((100, 100)),\n",
    "    # T.RandomRotation(10),\n",
    "    # T.RandomAffine(degrees=10, translate=(0.05, 0.05), scale=(0.95, 1.05)),\n",
    "    # T.ColorJitter(brightness=0.25, contrast=0.5),\n",
    "    T.ToDtype(torch.float32, scale=True),\n",
    "    T.Normalize(mean=[0.5], std=[0.5]),  # Cân chỉnh lại nếu bạn có thống kê cụ thể hơn\n",
    "])\n",
    "\n",
    "\n",
    "# Transform cho dữ liệu train và validation\n",
    "train_transform = T.Compose([\n",
    "    T.ToImage(),                            # Chuyển sang định dạng tensor\n",
    "    T.Grayscale(num_output_channels=3),     # Chuyển ảnh xám sang 3 kênh để tương thích với EfficientNet\n",
    "    T.Resize((384, 384)),                   # Resize về kích thước 384x384 (yêu cầu của EfficientNetV2-S)\n",
    "    T.RandomRotation(10),                   # Augmentation: xoay ngẫu nhiên ±10 độ\n",
    "    T.RandomAffine(degrees=0, translate=(0.05, 0.05), scale=(0.95, 1.05)),  # Dịch chuyển và thay đổi tỷ lệ\n",
    "    T.ColorJitter(brightness=0.25, contrast=0.5),  # Thay đổi độ sáng và độ tương phản\n",
    "    T.ToDtype(torch.float32, scale=True),   # Chuyển sang float32 và scale về [0, 1]\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Chuẩn hóa theo ImageNet\n",
    "])\n",
    "\n",
    "# Transform cho dữ liệu test (không augmentation)\n",
    "test_transform = T.Compose([\n",
    "    T.ToImage(),\n",
    "    T.Grayscale(num_output_channels=3),\n",
    "    T.Resize((384, 384)),\n",
    "    T.ToDtype(torch.float32, scale=True),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfc7c993",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T17:09:38.559795Z",
     "iopub.status.busy": "2025-06-09T17:09:38.559588Z",
     "iopub.status.idle": "2025-06-09T17:09:38.570075Z",
     "shell.execute_reply": "2025-06-09T17:09:38.569591Z"
    },
    "papermill": {
     "duration": 0.016223,
     "end_time": "2025-06-09T17:09:38.571042",
     "exception": false,
     "start_time": "2025-06-09T17:09:38.554819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyheif\n",
    "import torch\n",
    "\n",
    "\n",
    "def convert_heic_to_jpeg(heic_path, jpeg_path):\n",
    "    try:\n",
    "        heif_file = pyheif.read(heic_path)\n",
    "        image = Image.frombytes(\n",
    "            heif_file.mode, \n",
    "            heif_file.size, \n",
    "            heif_file.data, \n",
    "            \"raw\", \n",
    "            heif_file.mode, \n",
    "            heif_file.stride,\n",
    "        )\n",
    "        image.save(jpeg_path, format=\"JPEG\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\t🛑 Lỗi chuyển đổi .heic: {heic_path} — {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1bce93e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T17:09:38.580561Z",
     "iopub.status.busy": "2025-06-09T17:09:38.580370Z",
     "iopub.status.idle": "2025-06-09T17:09:38.587918Z",
     "shell.execute_reply": "2025-06-09T17:09:38.587436Z"
    },
    "papermill": {
     "duration": 0.013375,
     "end_time": "2025-06-09T17:09:38.588814",
     "exception": false,
     "start_time": "2025-06-09T17:09:38.575439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "\n",
    "\n",
    "def read_heic(img_path):\n",
    "    jpeg_path = \"heic2jpeg/\" + img_path.split(\"/\")[-1].replace(\".HEIC\", \".jpeg\")\n",
    "    convert_heic_to_jpeg(img_path, jpeg_path)\n",
    "    image = read_image(jpeg_path, mode=\"RGB\")\n",
    "    return image\n",
    "    \n",
    "\n",
    "class custom_image_dataset(torch.utils.data.IterableDataset):\n",
    "    def __init__(self, image_lists, transform=None, test=False):\n",
    "        # self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.image_lists = image_lists\n",
    "        self.transform = transform\n",
    "        self.test = test\n",
    "\n",
    "    def __read_image(self, img_path):\n",
    "        try:\n",
    "          if img_path.endswith(\".HEIC\"):\n",
    "              image = read_heic(img_path)\n",
    "              if image is not None:\n",
    "                  print(\"--> Converted to JPEG\")\n",
    "              else:\n",
    "                  print(\"--> Can't convert to JPEG\")\n",
    "          elif img_path.endswith(\".md\"):\n",
    "              print(\"Found markdown\")\n",
    "              return None\n",
    "          else:\n",
    "              image = read_image(img_path, mode=\"RGB\")\n",
    "          truth = -1\n",
    "          if not self.test:\n",
    "              label_str = os.path.basename(img_path).split(\"_\")[1]  \n",
    "              truth = torch.tensor(int(label_str))\n",
    "              \n",
    "          if self.transform:\n",
    "              image = self.transform(image)\n",
    "          return image, truth, img_path # Path sẽ rất cần để debug\n",
    "        except Exception as e:\n",
    "          print(f\"\\t**Error reading imgs: {e} - for: {img_path}\")\n",
    "          return None\n",
    "\n",
    "    def __iter__(self):\n",
    "        worker_info = torch.utils.data.get_worker_info()\n",
    "        if worker_info is None:  # single-process data loading, return the full iterator\n",
    "            iter_start = 0\n",
    "            iter_end = len(self.image_lists)\n",
    "        else:  # in a worker process\n",
    "            # split workload\n",
    "            per_worker = int(len(self.image_lists) / float(worker_info.num_workers))\n",
    "            worker_id = worker_info.id\n",
    "            iter_start =  worker_id * per_worker\n",
    "            iter_end = min(iter_start + per_worker, len(self.image_lists))\n",
    "        return iter(\n",
    "            filter(lambda x : x is not None\n",
    "                  , map(self.__read_image, self.image_lists[iter_start : iter_end] )\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_lists)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab758c3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T17:09:38.597929Z",
     "iopub.status.busy": "2025-06-09T17:09:38.597727Z",
     "iopub.status.idle": "2025-06-09T17:09:38.601651Z",
     "shell.execute_reply": "2025-06-09T17:09:38.600970Z"
    },
    "papermill": {
     "duration": 0.009646,
     "end_time": "2025-06-09T17:09:38.602647",
     "exception": false,
     "start_time": "2025-06-09T17:09:38.593001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clear_heic2jpeg():\n",
    "    if not os.path.exists(\"heic2jpeg\"):\n",
    "        os.makedirs(\"heic2jpeg\")\n",
    "    else:\n",
    "        shutil.rmtree(\"heic2jpeg\")\n",
    "        print(\"deleted old folder 'heic2jpeg'\")\n",
    "        os.makedirs(\"heic2jpeg\")\n",
    "        print(\"Created new 'heic2jpeg'\")\n",
    "\n",
    "\n",
    "clear_heic2jpeg()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ba6ec09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T17:09:38.611617Z",
     "iopub.status.busy": "2025-06-09T17:09:38.611422Z",
     "iopub.status.idle": "2025-06-09T17:09:38.684593Z",
     "shell.execute_reply": "2025-06-09T17:09:38.683923Z"
    },
    "papermill": {
     "duration": 0.078876,
     "end_time": "2025-06-09T17:09:38.685689",
     "exception": false,
     "start_time": "2025-06-09T17:09:38.606813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 7\n",
      "/kaggle/input/handwritten-tl/digits_data/train/7/train_7_7_b_002_0135.jpg\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCABkAGQBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APfaKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKQkDqRTI5UlXMbKy+qtmpKKKKKKKKKTqK5bxH420nwsFivJi1yw3Jbx8yFeeT6ZwQM4zg9cHHEQ6N4y8eTGXVZZdGsI02rGoZSzbXGQmc5BYAg4yDjJwaPAWnP4d+Jmr6JBO81rFbAlyfdCo4IGcyN1Bwc4xk59hoooooooopua5a68EaRqHiR9avRLdysFCRTHdHGAAMKuOh5JGccniuoOAvsK8y+HMn9peL/FOrJ+4jedUMH3+csQ2/kHjspx83TG2vUKKKKKKKKKaBjtSM6oCScVxvinxvo+n6LfJBqdm955GYoxiUMXUlflB+ZTxz0AIJ46+b+DvHtxoWjpoum6K17dSyM6MG/wBYTywCqpPAKDk9+cYAr3DT5pZ9Ptpp4vJlliV5I8k+WxGSuWAOB05APsKu0UUUUUUUnFcp4v8ADE3ii3gtl1J7OGIsziOPcXYoQOcg7QGbIH3s44xXlPijwjplj4r0vw3pQk8+faZZpn8xSWwuCqYZcbSeCB83t8vu9rZ29nbiK3hWNOSQF6knJJ7kk96t0UUUUUUUUUhIAJryjwXJ/wAJR8R9Y15jP5NoBDDHNLtePORho8A7SQxGeh9SMj1fpS0UUUUUUUUVj+Irj7L4c1OYySRCO1lbzIiFZcITlSeARjOTwO9cp8JNNlsvB4e5txE9zK0ozHtZ0wApbJ9j+BH1PoIPWnUUUUUUUUUUUYx0oooooooor//Z",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=100x100>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp = custom_image_dataset(train_list[:10], transform=transform)\n",
    "it = iter(temp)\n",
    "img, truth, path = next(it)\n",
    "\n",
    "print(f\"label: {truth}\")\n",
    "print(path)\n",
    "\n",
    "display(to_pil_image(img))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "627c77e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T17:09:38.695634Z",
     "iopub.status.busy": "2025-06-09T17:09:38.695440Z",
     "iopub.status.idle": "2025-06-09T17:09:38.701573Z",
     "shell.execute_reply": "2025-06-09T17:09:38.700916Z"
    },
    "papermill": {
     "duration": 0.011933,
     "end_time": "2025-06-09T17:09:38.702564",
     "exception": false,
     "start_time": "2025-06-09T17:09:38.690631",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num workers: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "num_workers = os.cpu_count()\n",
    "print(f\"Num workers: {num_workers}\")\n",
    "trainset = custom_image_dataset(train_list,transform=train_transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, num_workers=num_workers)\n",
    "\n",
    "valset = custom_image_dataset(val_list, transform=test_transform)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=BATCH_SIZE, num_workers=num_workers)\n",
    "\n",
    "classes = [i for i in range(10)]\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfde0a9",
   "metadata": {
    "papermill": {
     "duration": 0.004296,
     "end_time": "2025-06-09T17:09:38.711341",
     "exception": false,
     "start_time": "2025-06-09T17:09:38.707045",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Model config**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a88ce9dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T17:09:38.720717Z",
     "iopub.status.busy": "2025-06-09T17:09:38.720494Z",
     "iopub.status.idle": "2025-06-09T17:09:38.727557Z",
     "shell.execute_reply": "2025-06-09T17:09:38.726911Z"
    },
    "papermill": {
     "duration": 0.012904,
     "end_time": "2025-06-09T17:09:38.728563",
     "exception": false,
     "start_time": "2025-06-09T17:09:38.715659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "from contextlib import redirect_stdout\n",
    "\n",
    "# Ghi cả ra file và màn hình\n",
    "class DualWriter:\n",
    "    def __init__(self, file):\n",
    "        self.file = file\n",
    "        self.stdout = sys.__stdout__  # console thật\n",
    "\n",
    "    def write(self, text):\n",
    "        self.stdout.write(text)\n",
    "        self.file.write(text)\n",
    "\n",
    "    def flush(self):\n",
    "        self.stdout.flush()\n",
    "        self.file.flush()\n",
    "\n",
    "class SaveBestModel:\n",
    "    def __init__(self, save_path=\"best_model.pth\", mode='min'):\n",
    "        self.best_value = float('inf') if mode == 'min' else -float('inf')\n",
    "        self.save_path = save_path\n",
    "        self.mode = mode\n",
    "\n",
    "    def __call__(self, current_value, model):\n",
    "        is_better = current_value < self.best_value if self.mode == 'min' else current_value > self.best_value\n",
    "        if is_better:\n",
    "            self.best_value = current_value\n",
    "            torch.save(model.state_dict(), self.save_path)\n",
    "            print(f\"✅ Saved new best model ({self.mode} = {current_value:.4f})\")\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, mode='min'):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_value = float('inf') if mode == 'min' else -float('inf')\n",
    "        self.early_stop = False\n",
    "        self.mode = mode\n",
    "\n",
    "    def __call__(self, current_value):\n",
    "        is_better = current_value < self.best_value if self.mode == 'min' else current_value > self.best_value\n",
    "\n",
    "        if is_better:\n",
    "            self.best_value = current_value\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            print(f\"⚠️ No improvement. EarlyStopping counter: {self.counter}/{self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfc6d499",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T17:09:38.738481Z",
     "iopub.status.busy": "2025-06-09T17:09:38.737946Z",
     "iopub.status.idle": "2025-06-09T17:09:40.192295Z",
     "shell.execute_reply": "2025-06-09T17:09:40.191694Z"
    },
    "papermill": {
     "duration": 1.460457,
     "end_time": "2025-06-09T17:09:40.193587",
     "exception": false,
     "start_time": "2025-06-09T17:09:38.733130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/efficientnet_v2_s-dd5fe13b.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_v2_s-dd5fe13b.pth\n",
      "100%|██████████| 82.7M/82.7M [00:00<00:00, 213MB/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class EfficientNetV2S(nn.Module):\n",
    "    def __init__(self, num_classes=10, pretrained=True):\n",
    "        super(EfficientNetV2S, self).__init__()\n",
    "        # Tải mô hình EfficientNetV2-S pre-trained\n",
    "        self.model = models.efficientnet_v2_s(weights='IMAGENET1K_V1' if pretrained else None)\n",
    "        \n",
    "        # Đóng băng các tham số của mô hình pre-trained (nếu muốn)\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Thay thế lớp fully connected cuối cùng\n",
    "        # EfficientNetV2-S có lớp cuối là Linear(in_features=1280, out_features=1000) (ImageNet có 1000 lớp)\n",
    "        # Ta thay bằng Linear(in_features=1280, out_features=num_classes)\n",
    "        self.model.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.2, inplace=True),  # Giữ dropout như trong mô hình gốc\n",
    "            nn.Linear(1280, num_classes)      # Thay đổi đầu ra thành num_classes\n",
    "        )\n",
    "        \n",
    "        # Mở khóa các tham số của lớp classifier để huấn luyện\n",
    "        for param in self.model.classifier.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Khởi tạo mô hình\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = EfficientNetV2S(num_classes=10, pretrained=True).to(device)\n",
    "\n",
    "# Định nghĩa loss function và optimizer\n",
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Chỉ tối ưu hóa lớp classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e381e681",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T17:09:40.204752Z",
     "iopub.status.busy": "2025-06-09T17:09:40.204529Z",
     "iopub.status.idle": "2025-06-09T17:09:40.209803Z",
     "shell.execute_reply": "2025-06-09T17:09:40.209162Z"
    },
    "papermill": {
     "duration": 0.011972,
     "end_time": "2025-06-09T17:09:40.210748",
     "exception": false,
     "start_time": "2025-06-09T17:09:40.198776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số tham số huấn luyện được: 12810\n"
     ]
    }
   ],
   "source": [
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Số tham số huấn luyện được: {trainable_params}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "372caf84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T17:09:40.221016Z",
     "iopub.status.busy": "2025-06-09T17:09:40.220826Z",
     "iopub.status.idle": "2025-06-09T17:16:51.226961Z",
     "shell.execute_reply": "2025-06-09T17:16:51.226091Z"
    },
    "papermill": {
     "duration": 431.018406,
     "end_time": "2025-06-09T17:16:51.233940",
     "exception": false,
     "start_time": "2025-06-09T17:09:40.215534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cuda\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  50%|█████     | 1/2 [03:36<03:36, 216.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 2.1974 - time: 216.4623851776123s\n",
      "✅ Saved new best model (min = 2.1974)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 2/2 [07:10<00:00, 215.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🟢 Đã ra khỏi with, chỉ in ra console, không ghi file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "if os.path.exists('train_log.txt'):\n",
    "    os.remove('train_log.txt')\n",
    "    print(\"Deleted old 'train_log'.\")\n",
    "# Ghi log ra log.txt\n",
    "log_file = open(\"train_log.txt\", \"a\")  # mở log file\n",
    "dual_output = DualWriter(log_file)\n",
    "save_best_model = SaveBestModel(\"best_model.pth\", mode='min')\n",
    "early_stopping = EarlyStopping(patience=5, mode='min')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using: {device}\")\n",
    "model.to(device)\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "with redirect_stdout(dual_output):\n",
    "    for epoch in tqdm(range(2), desc=\"Epochs: \"):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        print()\n",
    "        epoch_start = time.time()\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels, _ = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # print(inputs.device, labels.device, next(net.parameters()).device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        epoch_loss = running_loss / len(trainloader)\n",
    "        print(f\"Epoch {epoch+1} loss: {epoch_loss:.4f} - time: {time.time() - epoch_start}s\")\n",
    "\n",
    "        # Gọi callback\n",
    "        save_best_model(epoch_loss, model)\n",
    "        early_stopping(epoch_loss)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print(\"⛔ Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print(f'Finished Training in: {total_time}s')\n",
    "    \n",
    "print(\"🟢 Đã ra khỏi with, chỉ in ra console, không ghi file\")\n",
    "log_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "287a84e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T17:16:51.245500Z",
     "iopub.status.busy": "2025-06-09T17:16:51.245261Z",
     "iopub.status.idle": "2025-06-09T17:17:40.006212Z",
     "shell.execute_reply": "2025-06-09T17:17:40.005163Z"
    },
    "papermill": {
     "duration": 48.772869,
     "end_time": "2025-06-09T17:17:40.012256",
     "exception": false,
     "start_time": "2025-06-09T17:16:51.239387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted old folder 'heic2jpeg'\n",
      "Created new 'heic2jpeg'\n",
      "Accuracy of the network on the test images: 36.69 %\n"
     ]
    }
   ],
   "source": [
    "#validate\n",
    "if not os.path.exists(\"heic2jpeg\"):\n",
    "    os.makedirs(\"heic2jpeg\")\n",
    "else:\n",
    "    shutil.rmtree(\"heic2jpeg\")\n",
    "    print(\"deleted old folder 'heic2jpeg'\")\n",
    "    os.makedirs(\"heic2jpeg\")\n",
    "    print(\"Created new 'heic2jpeg'\")\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = EfficientNetV2S(num_classes=10, pretrained=True)\n",
    "model.load_state_dict(torch.load('best_model.pth', map_location=device))\n",
    "model.to(device)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in valloader:\n",
    "        images, labels,_ = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy of the network on the test images: {accuracy:.2f} %')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940c5fe4",
   "metadata": {
    "papermill": {
     "duration": 0.00513,
     "end_time": "2025-06-09T17:17:40.022825",
     "exception": false,
     "start_time": "2025-06-09T17:17:40.017695",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **PREDICT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "deb328b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T17:17:40.035451Z",
     "iopub.status.busy": "2025-06-09T17:17:40.035196Z",
     "iopub.status.idle": "2025-06-09T17:18:48.559736Z",
     "shell.execute_reply": "2025-06-09T17:18:48.558901Z"
    },
    "papermill": {
     "duration": 68.532888,
     "end_time": "2025-06-09T17:18:48.560998",
     "exception": false,
     "start_time": "2025-06-09T17:17:40.028110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted old folder 'heic2jpeg'\n",
      "Created new 'heic2jpeg'\n",
      "samples: 2939\n",
      "--> Converted to JPEG\n",
      "--> Converted to JPEG\n",
      "Found markdown\n",
      "--> Converted to JPEG\n",
      "--> Converted to JPEG\n",
      "--> Converted to JPEG\n",
      "--> Converted to JPEG\n",
      "Found markdown\n",
      "Found markdown\n",
      "--> Converted to JPEG\n",
      "--> Converted to JPEG\n",
      "Found markdown\n",
      "--> Converted to JPEG\n",
      "--> Converted to JPEG\n",
      "Found markdown\n",
      "--> Converted to JPEG\n",
      "Found markdown\n",
      "--> Converted to JPEG\n",
      "--> Converted to JPEG\n",
      "Found markdown\n",
      "--> Converted to JPEG\n",
      "--> Converted to JPEG\n",
      "Found markdown\n",
      "--> Converted to JPEG\n",
      "--> Converted to JPEG\n",
      "Found markdown\n",
      "--> Converted to JPEG\n",
      "--> Converted to JPEG\n",
      "Found markdown\n",
      "--> Converted to JPEG\n",
      "--> Converted to JPEG\n",
      "--> Converted to JPEG\n",
      "--> Converted to JPEG\n",
      "--> Converted to JPEG\n",
      "--> Converted to JPEG\n",
      "--> Converted to JPEG\n",
      "--> Converted to JPEG\n",
      "Found markdown\n",
      "--> Converted to JPEG\n",
      "--> Converted to JPEG\n",
      "--> Converted to JPEG\n",
      "Predictions saved in 'predict.txt'\n"
     ]
    }
   ],
   "source": [
    "# PREDICT\n",
    "clear_heic2jpeg()\n",
    "test_dir = \"/kaggle/input/handwritten-test-cs114\"\n",
    "test_list = [os.path.join(test_dir, img) for img in os.listdir(test_dir)]\n",
    "print(f\"samples: {len(test_list)}\")\n",
    "testset = custom_image_dataset(test_list, transform=test_transform, test=True)\n",
    "testloader = torch.utils.data.DataLoader(testset,batch_size=BATCH_SIZE, num_workers=num_workers)\n",
    "\n",
    "predict_txt = \"\"\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels, paths = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # save\n",
    "        for path, pred in zip(paths, predicted):\n",
    "            path = path.replace(test_dir, \"\").lstrip(os.sep)  # Strip test_dir and leading separator\n",
    "            predict_txt += f\"{path},{pred.item()}\\n\"\n",
    "\n",
    "# Write to file in text mode\n",
    "with open(\"/kaggle/working/predict.txt\", \"w\") as file:\n",
    "    file.write(predict_txt)\n",
    "print(\"Predictions saved in 'predict.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64935bbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T17:18:48.579434Z",
     "iopub.status.busy": "2025-06-09T17:18:48.579194Z",
     "iopub.status.idle": "2025-06-09T17:18:48.670595Z",
     "shell.execute_reply": "2025-06-09T17:18:48.669832Z"
    },
    "papermill": {
     "duration": 0.101761,
     "end_time": "2025-06-09T17:18:48.671761",
     "exception": false,
     "start_time": "2025-06-09T17:18:48.570000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: -1\n",
      "/kaggle/input/handwritten-test-cs114/389269258327f495063eeb7863aeb323  -.jpg\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=100x100>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp = custom_image_dataset(test_list[:10], transform=transform, test=True)\n",
    "it = iter(temp)\n",
    "img, truth, path = next(it)\n",
    "\n",
    "\n",
    "print(f\"label: {truth}\")\n",
    "print(path)\n",
    "\n",
    "display(to_pil_image(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c9a1a4",
   "metadata": {
    "papermill": {
     "duration": 0.008514,
     "end_time": "2025-06-09T17:18:48.689305",
     "exception": false,
     "start_time": "2025-06-09T17:18:48.680791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a12e1277",
   "metadata": {
    "papermill": {
     "duration": 0.008278,
     "end_time": "2025-06-09T17:18:48.705994",
     "exception": false,
     "start_time": "2025-06-09T17:18:48.697716",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **PREDICT 10K**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "321a8eba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T17:18:48.724069Z",
     "iopub.status.busy": "2025-06-09T17:18:48.723549Z",
     "iopub.status.idle": "2025-06-09T17:23:45.248560Z",
     "shell.execute_reply": "2025-06-09T17:23:45.247510Z"
    },
    "papermill": {
     "duration": 296.544045,
     "end_time": "2025-06-09T17:23:45.258496",
     "exception": false,
     "start_time": "2025-06-09T17:18:48.714451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted old folder 'heic2jpeg'\n",
      "Created new 'heic2jpeg'\n",
      "samples: 9974\n",
      "Predictions saved in 'predict_10k.txt'\n"
     ]
    }
   ],
   "source": [
    "# PREDICT\n",
    "clear_heic2jpeg()\n",
    "test_dir = \"/kaggle/input/handwritten-test-10k\"\n",
    "test_list = [os.path.join(test_dir, img) for img in os.listdir(test_dir)]\n",
    "print(f\"samples: {len(test_list)}\")\n",
    "testset = custom_image_dataset(test_list, transform=test_transform, test=True)\n",
    "testloader = torch.utils.data.DataLoader(testset,batch_size=BATCH_SIZE, num_workers=num_workers)\n",
    "\n",
    "predict_txt = \"\"\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels, paths = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # save\n",
    "        for path, pred in zip(paths, predicted):\n",
    "            path = path.replace(test_dir, \"\").lstrip(os.sep)  # Strip test_dir and leading separator\n",
    "            predict_txt += f\"{path},{pred.item()}\\n\"\n",
    "\n",
    "# Write to file in text mode\n",
    "with open(\"/kaggle/working/predict_10k.txt\", \"w\") as file:\n",
    "    file.write(predict_txt)\n",
    "print(\"Predictions saved in 'predict_10k.txt'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f7638f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T17:23:45.326755Z",
     "iopub.status.busy": "2025-06-09T17:23:45.325881Z",
     "iopub.status.idle": "2025-06-09T17:23:45.407517Z",
     "shell.execute_reply": "2025-06-09T17:23:45.406813Z"
    },
    "papermill": {
     "duration": 0.092655,
     "end_time": "2025-06-09T17:23:45.408619",
     "exception": false,
     "start_time": "2025-06-09T17:23:45.315964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: -1\n",
      "/kaggle/input/handwritten-test-10k/167144297687438af7bff077e768440c.jpg\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAAAAABVicqIAAATyklEQVR4AT3aXahte1nH8bHGHnue2XKzOe5UIixOEl500TGNRAxCpReNCLESJYgy6TbpouIUImI3IhYRYhIUEURFCuJVlGUvGhwINNRsYwcpO5yOR9uspvPMPdbYfb7/eXTuudac4//yvPye3/P8nzHWvvi5bVmndZnmaTnM07zN3tO2LdvU5zIvh2XadtM2zfM8TRbsT6s1Zo1OVk7LtiyTt5F5taZvFlr63KcRG9q+TUcybSZ4fLFsWubV2Lyke54It/mYHT7n7bhMp3lh4zztKNvMD0mJydDZJ4Xr+DTQWGb2ax32bPNpWbIlc1LFbN83qjK5ZTMV23baptP+RDoP6Gt5gvPpjEa7MiGL2ZuPDLbuuJ1OTCV5bX9ebcbXNbOBk7z1uPc737eGZxfM6tccGl5JSp4BkmBkU4J2J8MUrtu2P3u3y7smjWfMsKlN63Kado0TvZtTZ+N8jg3FlPhuFZusyse8TLgwmGfCbp7XRDBfaAsvnSPklmeJOFBttcvLDbbDjAwdMQbsiQxqeZKO9oYhiSf/aG9vBHAVE5I04n3WQszKzxkpk7zut+lwu+3pzgUGmUAZ1uadiSBgqa2hwsek+jFKNX+bcrXu8tMO7u8GF060mA8Rfp41BDUNNthLkM/k5ZLthjPCFb++SSxmgDunWhBiu2FbWGU4rwPqNlKgxACleARRSO8yL7jZOE+MIqmZIatUGVxLBSFxweQ07VcQkGh6OIiDe0KQwPJsIMvPYOzZvwDzEwrT6czPaT7xLWASfTiQeyJ9GO4TWCfa8HSZyU3/dCo/B7yWhQ89fQ74BgZ0uyIHaaPxcK1cbz1oqjglnKyTDct6XHeXsf90OkEqLTahSxqzWHBIQk5a0lkIBkghmXnD4mgvXaIEybeGccMrgBsBWwGjZrocyZ9B01UMHrjGP94m1+LG1La84p7vGGnv0C/lSxSuneRKOcURER6G2jniOiAouOQjMYwLkrUWJEvQslsseUi3FfM6Moxerqiwu6vtcKzImBOnCE9q2CQvnDggzIZOs3qcfUxn8hnYkRdDbsmYwrzhxiF688LHst26hGwkYAdOhUplN2qyjmzFJNWctSfZu5Tl2DgZEpo367KiSAE3cuKCtbTuouc2H7btOGRPWGuFWECBFRSbUPNj0Tzfus2+QFJUrYMfhvSlH18cN8uCkpS6rlwOBwPD25VxprFWISMEJ/xgtmHHTyH2jZzWV2XtiuW9zlzLPMbjZDITnKIKu0pRgELqLAmq82E3HFmAajkcM2yJNONcZRPtVTPe05iXQwJCLycCuBDBvDOd6EqEt7WpEgih4EkncaYMB4YVmbVejm3ZxlI7WMh7CysOLcNvII6RXBmvsyqD215RpzW5M1hbTOogA9t4y/gNKXaujI+acoJtXmQx5DK+kCxMcDzkYDVofIW3U/WKECwwsY6GAjnazjV+dfyOY+twK21MXS9Zw5FzXXPuFwO/F7ngyyrpGCWu0TLWsX4/Qp/dkaoAxwG2zXsn864c1QhEDF2IGQOnit5IFgA9R4EYi4wW7YaJdpUkQALFjr2CA4lR8gYGgloYcm67ApF9l5SMChGB2DDs7Mit/lg8zfdY6FW5CmpwGA1I01LndGRDZcHWFaFSF0Ha62OnSkgNwTjWe0iPnet9diVl3z7v/ciMTT20T99WRiOcuWU5Uj1MsGO1oXzwD7ZMGposPG3rPnp0zTihroANj1wrBrzBffyU3BD2QdMpeIeoYtUiVZQEnAgrBQVchlzYT13HSmFXP9XTU/XC7Cg5aSNf5Mg68gwLTuUTAiwLj8uVYlEWZefACKSRgUJDYoeLgpkHEDwzeJTMLBggFNqBno9shxBwWZ2QCnTrksDZuAjnecfrDoyhPzt5UvIQaJfRQaw6tbwxuSc4JwusmPuIixy4tJGmmiFVteDRfrSwZfsDiXgjfmdShdQ0X5oS9uPpkqrjXoxTVxsBS0oy8TTdu01DflNquANEZpUgiAglTo94j8w9HuS2jmLd6RyJI8vvUS+dBp1QfhXAHMKpNNi/w55BEYrCabxWOStNeZ0TfsJqWw6P/9Hjz1y+9R2LbIXmYb847hEn4UF+dbmsu4OCddobOJJ38ePJI4B2/peleSEOu93RmUWP7+as3tfSrf/6gd/58p2n773oYz/fqUXwgja82PGUP6W3JMhqES5n1vniNcNKakDLruJ1gpjD0EV5OCoMdK/0V7vTk3/12N1XvvXlT/zZB1/7N48kAFaHh+eljrv9NgiG2MUmxpaW88XroOTTEkIhlc7iVLnKC96Nswakpr/8/vfcee+bX7Bsj7/siQ+9x7oRrZ3OeC/po3ZOFRBkjbTu1Hb7ReGoGPE61Eye88N0nioqSp6omRGpu+957Ac/+OoXsPRFL7r7+LoeL20QAjaHDbIquKQQqfAZ2m3HQimyx+NVBeLkjD4erq5CFVD8igpwKIf4ejr880/97pv+4hVEHK7WF0yfe2q9rKAdiD7Nx/KuU369orGiEGyO9l0qc07OKIBpMRib4rXJLBR13iHZ9G9v+6d3/fEjdQXzl9/++PT5z8BdW3Y8StYCfoRKTsM3zGwaUkDWgqFaWGAC0wMm7ZUoqeGKTVfdeM7rU7/xqXe+++H1dPd/vuM7t5/9gV958iPgYRNf1c/QLuxx5ih8MAOYa19LgFWXy82cigOcZqK7WhgOTktZ2XT40J+86TGt1fqV49X64jf90vdvn41QDnJy1uPmsBx1jsxqErROVzAcdNNDHUeROvuRWZLMRsDxEV06acD4ufe/+LfuCM/lo696BLb7V83/rTPDUl6MMpTblsedQVzmm+eBjDx0FpYfhSLvViL5NBjN+wqZqnL607tve1RdcoK0fHr67vzUvbCP9bvhNoVnS6tqEYcS/a6MzeECy16wMtpCDlf1CaMEazayn/nzOz9DgcM2jOYn3/HR+eoQBEe2uh/vhnwQgJ6hOC0ksFyNXHZKx7Ts9lhAtdNMZSsR6Y2JFRTr/uuJb3/hEXS8xPq/f/OHf/V7v/bVGg7/gCkbdHDjzv+MwoioIE1a2jMswL932hDcpnKoMNAULeysmq/7y4Ny3w3EvH7xvT/x73/wrtdf3dWrOOkYaofFhwNt8YficUqNbFNhIkb6QkisWTlm4lMkKVvwZt591yu++IEvZckXPv6bP/Lrr/7oG5dHTp/n4uXgbsQFMjoXSxCMIIy4Z6eCSQ7kCyiPgNWrdZ2xEWE67uf18pf/+d1veM2dZ774L69bX/ahn/zwst2Zn87PpEO1zC4cdVECfbUHlXRBTNQmNR3JEuZJIg3pfJOQUWHRchw8Gvjhv/vtv/7Utrvzkjf+2Pd96mHA35qf1jlYklC65AQpzo8ystuPps4dQXcENZym+HlyAIz2wLQKIdI4qoOKIz90+szd5fIl3/oP77vjiulQ2MN3wjgtWnjn2VDXei8igSKxxTkPaDBUaeeiG5xLpGjZcnDmk3BYdssrj+j0MOfZ1JfD6XinZl8tlk8FlGUd5hkchp03iHcu9aIlWwZQom3FOt+TyOxYplv4c5xKiXXfSWgwYNzx4twtYhSJEktA+c6sxIY8dYzPaO7lRq9bQsar+pcaNR2Kzlr1xQgbuLwdKmrVvHp6rOzMGPW6DpaD4oBLdESExOch+VlA4UgFlmXSIErYHS+PmuoCG9dsnm7Z232rQRjK4MpzROEGLbrQ0RMQw/pwcEDY5zIO1JvG4SoYSMN82EuIQ4KB1WkmBqnC6fs0feH0bbMnHgAqd+nicCXA9xqO7OijuLYcIjoPashDwSs3DblHl+ZqRIE1AiFegg6Mxg6fWF4+aSKY2jvkEyVGVtlP22glmcs4/RqHwXC8KmLEO3bVq/V4KEOjHO2YrjJJTKAH3vrhj3/PGypChbeGmPWEkF2MOR8R+orApLMgHy25jE3wjxmn+arjHdx2RARAcb5eLbuOH3vH8tjntZHE1rGAzNF/biXtEZBak5zjhyAwtVbUbhSvsIvfbcm1pyiAqI607F0XHbDP0/zk77399M6f3iv9nAsNYRsiYgCnaxSH+pExF8+fd6MWw+fBzeX/tpvz9uBiuu0823YsExKFqy40ouhO7JqvPvm+v33k3W92VC3SvQM0AzNbFdjVdK+XQVRUBamsuILHtH79oesb67Pr/OygJJUQeDD4Z7owyBOWo9L/fvr33zK/5dcezfKTPofxsLSkL3kM0pg4QMuj9eJ57rFl1vU237hGGkKClD/+ccK2AhUkLDos21c+8ZefXH/0F195K+PX+XJvjnNxmDiBGzABVrwd7hTP08VNFj673bz/XJDyWVButLTvvXb/8cyLn+/7/OzVZz/yj0/ces0vvOqyRKd93nULEmMHhYemglpM3KFjM5atFxfz/XLPXSgnygbPuDX91Mz3L6z2BHr53B8+c7lfrg5ffeo/t+9+/WsfpUI5iULLfp8XGn4Dhzxm0zg+Jw/9LKnUTBfrzesB+tmFblPjvmlb+duSBze+/qVPf/bJ03L7kdsvfekLi+UODtaBcNdDQl4nP+r7DAX7zvcvQN4uhKFCEDIhlXaPVCzUTF+5X5VC88V9loTKDdOE1FclaRzkLWBMcEKJdA7azgP1Of1OZcJZ0ERqhN5J1DGWzP3N6XqbHrpx3/6bF7N3QtrgrwXMVvm9aRm7zXRag72R/MtyU9tF9ao7pnwZfwEQrja55QjJXAPYOt184LZsevZ51o2AjAzSChf4pFVu/ZQWRjjrl0KRkupBRwXd0ZfTfq4OzJSi27PHmrZtu8aXBzemG/cfPJQE2VJZcruYBeFzLiBBEgYVMdzP6szdThfJIcjKfBm/WSD6co0/wy6j8eIG5jiOWmO4XPT4hh4h4kDQeFWJeGRBMYuzKHyvq05le8EcsQ34Z10Nho+jwjFEufubpgcXDy7O/h8vnUSyjpnAo92GzBzKwAMr/CRwNBJBMIIy8GKUz3EWqFwaDU6NmjrP5E8X18oB6Z2WBPQ9wEJnBAcoQBTMwoE9QBsP2RspL0brV5PfsXY2SGdWaXHHHHKCP0Pt/vV0nQrH4nPrcni820zvGKamyCHO13z0jTpSwBlkPrKGKXwmnUUuzn/CUAsFZ7q+Yfd2OXuoRq5mMWBwsfKVKVXAhnrnrv1pHqmDFGeXBtu0wWYJq/3w4CHl2+nGg+nBg/maFQQ6RhXYymRPihPahogVtZzyXVeXmZmlrTHGXSIp83b8lldDeBTzurEITL7Mk5OhTGAjWR1UY8+Q37aBZS5wpbTJUx6Af+humEohtzgym8DLqDdfbxedM9nzkD/SlvpZa6BXJbxoVzu8csTp7Q5DheJs1oeMBS714tofDC5X6rX0oOqCVkU40jBP1zc7693HEtYWAotdFmmnd+MJRl6OqTqEIClEFaMB43SvGxcwwKx9KJq7rWm5fxcXSOZvT6XCwLZ0QJkxCXAguBxRKd6+ny+iO/hdrzXy3Bqq64xyQbsXPZ/Tcn19ceHJ9tIfH+gpWUQeM1g+Lp1SQUScvi43xsZhYllJlCCPp1vGSC1anFmWg2hlk83bVmikUI121yMUtcmUHHcVlATztDQY2jh5ZjarfIPD0mmXTUn0VRXV3dklCKOizhfXD41QD1TOp/u4behxRyQhs+05ily0SpKeTIQUZLKqaPji11gdIRnpqjI1usxnqxDm7WFZt1r84noiI6s7OTCX0H7Ux+cwUcLPXqZtWBkhSCJZROyL04POuHC1V2YCiszEVl2JszVP0wb7xf0huBplRjU8yUWhJ4qIdT7j7cyS3G/WMylXBF7cmm6Op8JjQTM0pYunZy1cHF/PXDIYFmcGDGu6Rxhj5ZReunj7qRfNN38i274+LzcqAuMktnUYNaQGahZ3R1JX2L2FfVlHKg/zt79ZAXPcqoQQ8X50gbzOGS8FmN3Xut6cHPaMCuMblJy7Pvk26BDRmIkvtMXw/u4i18dzMAbTarI/qtiFVhHUWP/7ghKvsBk4aNdcVR1CL3+tZMI34KF3cD1MA9Xankv4u0bMaWTcTca7Hp7kK1p185EPpGazp86MHytpYbzBcqR4NmWwky3A/AipQdtHUpLpqLB5AAY0Msf6isO4AH+K2plEKkfFLNmGQ+akA39HJlLXU94eXBhKSwZUTSxLhzErbQrGzNM0BUKq0xSoZm0ZhnXclRACGk9aLoRC7DQuuunQ9QCkCBWWFnEnxd8wmLTtwbCwhe0dvvS4J5uyRYLbiZIDrQGfvmZAkBcV60wa3OGvdz1gU6lqL6x327ewIIEIFWqmCo4zog3GrXIgjSDkeyWm9WNLz1fCzHt0opKPCvdyWFjV8OoJxzbrXMgktHxIaAt41Htg2DQDuih6ItGkwVGdWB4Bcs43cntOPuoOCNVoHUMwZQkLgNSrvX6lw1a/q8LjiQG/SDdvVTC6PxREy6wjeDTKmVDFbjO0gmJ0N4bDqPiQUZxD49wSlwAmSmPaintuDlWhkXbyh6vbYbhP7Lgkwa2yFEzUst68f2M4k7TCTE66BiJ9G9il9ry/XV3lgecT2dajTmMGvrnEbedgXUC1QueSwRk00n1oj/TjzYEzIEOv/DVqPWLA4tijiphG6xlFm4aiwCSxZ8cj5YcsNzHMcHNrSe1OtraciaQA2C8u1bbxNuRsi0HRAWQVktblWAHzWUAUHmbQNj9IDfFmbvhdyIg4i++gsg8rzsGsCGT34Pd51LbcbYZuL6wKZoZZaNj2tM7a1k2fNFaNhSkPqGaz6P8BeYCN4M+FU6IAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=100x100>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp = custom_image_dataset(test_list[:10], transform=transform, test=True)\n",
    "it = iter(temp)\n",
    "img, truth, path = next(it)\n",
    "\n",
    "\n",
    "print(f\"label: {truth}\")\n",
    "print(path)\n",
    "\n",
    "display(to_pil_image(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e91560",
   "metadata": {
    "papermill": {
     "duration": 0.008712,
     "end_time": "2025-06-09T17:23:45.426832",
     "exception": false,
     "start_time": "2025-06-09T17:23:45.418120",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Save**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afc83e41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T17:23:45.445359Z",
     "iopub.status.busy": "2025-06-09T17:23:45.444883Z",
     "iopub.status.idle": "2025-06-09T17:23:45.450157Z",
     "shell.execute_reply": "2025-06-09T17:23:45.449463Z"
    },
    "papermill": {
     "duration": 0.015665,
     "end_time": "2025-06-09T17:23:45.451196",
     "exception": false,
     "start_time": "2025-06-09T17:23:45.435531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "log_path = \"train_log.txt\"\n",
    "with open(log_path, \"a\") as f:\n",
    "    f.write(\"\\n\\n\" + \"=\"*60 + \"\\n\")\n",
    "    f.write(\"Training Summary\\n\")\n",
    "    f.write(\"=\"*60 + \"\\n\")\n",
    "    f.write(f\"Time: {total_time//60:.0f}m {total_time%60:.0f}s\\n\")\n",
    "    f.write(f\"Best Validation Accuracy: {accuracy:.4f}\\n\")\n",
    "    f.write(f\"\\nOptimizer: {optimizer.__class__.__name__} - {optimizer.state_dict()['param_groups'][0]}\\n\")\n",
    "    f.write(f\"Loss Function: {criterion.__class__.__name__}\\n\")\n",
    "    f.write(\"=\"*60 + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "893086c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T17:23:45.469455Z",
     "iopub.status.busy": "2025-06-09T17:23:45.469253Z",
     "iopub.status.idle": "2025-06-09T17:23:49.732950Z",
     "shell.execute_reply": "2025-06-09T17:23:49.732195Z"
    },
    "papermill": {
     "duration": 4.274586,
     "end_time": "2025-06-09T17:23:49.734560",
     "exception": false,
     "start_time": "2025-06-09T17:23:45.459974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: kaggle/working/ (stored 0%)\r\n",
      "  adding: kaggle/working/best_model.pth (deflated 7%)\r\n",
      "  adding: kaggle/working/predict.txt (deflated 50%)\r\n",
      "  adding: kaggle/working/__notebook__.ipynb (deflated 65%)\r\n",
      "  adding: kaggle/working/heic2jpeg/ (stored 0%)\r\n",
      "  adding: kaggle/working/train_log.txt (deflated 56%)\r\n",
      "  adding: kaggle/working/predict_10k.txt (deflated 47%)\r\n"
     ]
    }
   ],
   "source": [
    "!zip -r working.zip /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "546daca4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T17:23:49.754453Z",
     "iopub.status.busy": "2025-06-09T17:23:49.754190Z",
     "iopub.status.idle": "2025-06-09T17:23:49.776968Z",
     "shell.execute_reply": "2025-06-09T17:23:49.776462Z"
    },
    "papermill": {
     "duration": 0.03389,
     "end_time": "2025-06-09T17:23:49.778007",
     "exception": false,
     "start_time": "2025-06-09T17:23:49.744117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.remove(\"working.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2071e826",
   "metadata": {
    "papermill": {
     "duration": 0.008888,
     "end_time": "2025-06-09T17:23:49.796196",
     "exception": false,
     "start_time": "2025-06-09T17:23:49.787308",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **TEST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e41b9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T17:23:49.815122Z",
     "iopub.status.busy": "2025-06-09T17:23:49.814894Z",
     "iopub.status.idle": "2025-06-09T17:23:49.818005Z",
     "shell.execute_reply": "2025-06-09T17:23:49.817527Z"
    },
    "papermill": {
     "duration": 0.013651,
     "end_time": "2025-06-09T17:23:49.818983",
     "exception": false,
     "start_time": "2025-06-09T17:23:49.805332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "whats_new = \"\"\"\n",
    "- first transfer learning with EfficientNetV2-S\n",
    "- Preprocess match with EfficientNetV2-S input format\n",
    "-JUST 2 EPOCHS\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3b0561b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T17:23:49.837962Z",
     "iopub.status.busy": "2025-06-09T17:23:49.837417Z",
     "iopub.status.idle": "2025-06-09T17:23:49.844452Z",
     "shell.execute_reply": "2025-06-09T17:23:49.843894Z"
    },
    "papermill": {
     "duration": 0.017704,
     "end_time": "2025-06-09T17:23:49.845532",
     "exception": false,
     "start_time": "2025-06-09T17:23:49.827828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "heics = glob.glob(\"/kaggle/input/handwritten-test-cs114/*.HEIC\")\n",
    "print(len(heics))\n",
    "heics2jpegs = glob.glob(\"/kaggle/working/heic2jpeg/*\")\n",
    "print(len(heics2jpegs))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7608653,
     "sourceId": 12086766,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7613469,
     "sourceId": 12094235,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7614858,
     "sourceId": 12096088,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 875.521298,
   "end_time": "2025-06-09T17:23:53.163759",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-09T17:09:17.642461",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
