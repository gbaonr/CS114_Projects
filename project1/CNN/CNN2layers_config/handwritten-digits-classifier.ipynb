{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f4c20e9",
   "metadata": {
    "papermill": {
     "duration": 0.003922,
     "end_time": "2025-06-09T11:09:34.725384",
     "exception": false,
     "start_time": "2025-06-09T11:09:34.721462",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Data preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19f593ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T13:22:44.672669Z",
     "iopub.status.busy": "2025-06-10T13:22:44.672324Z",
     "iopub.status.idle": "2025-06-10T13:22:50.470640Z",
     "shell.execute_reply": "2025-06-10T13:22:50.469653Z",
     "shell.execute_reply.started": "2025-06-10T13:22:44.672650Z"
    },
    "papermill": {
     "duration": 4.175956,
     "end_time": "2025-06-09T11:09:38.904551",
     "exception": false,
     "start_time": "2025-06-09T11:09:34.728595",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install pyheif pillow -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "846b4397",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T13:22:33.082133Z",
     "iopub.status.busy": "2025-06-10T13:22:33.081869Z",
     "iopub.status.idle": "2025-06-10T13:22:44.670985Z",
     "shell.execute_reply": "2025-06-10T13:22:44.670153Z",
     "shell.execute_reply.started": "2025-06-10T13:22:33.082112Z"
    },
    "papermill": {
     "duration": 8.742941,
     "end_time": "2025-06-09T11:09:47.651147",
     "exception": false,
     "start_time": "2025-06-09T11:09:38.908206",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# transform data\n",
    "# transform data\n",
    "import torchvision.transforms.v2 as T\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from IPython.display import display\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.io import read_image\n",
    "from torchvision.io import decode_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cffe856",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T13:22:56.898785Z",
     "iopub.status.busy": "2025-06-10T13:22:56.898225Z",
     "iopub.status.idle": "2025-06-10T13:22:56.943934Z",
     "shell.execute_reply": "2025-06-10T13:22:56.943155Z",
     "shell.execute_reply.started": "2025-06-10T13:22:56.898760Z"
    },
    "papermill": {
     "duration": 0.331972,
     "end_time": "2025-06-09T11:09:47.986774",
     "exception": false,
     "start_time": "2025-06-09T11:09:47.654802",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True\n",
      "train: 5917, val: 1354\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "data_dir = \"/kaggle/input/handwritten-tl/digits_data\"\n",
    "train_dir = os.path.join(data_dir, \"train\")\n",
    "val_dir = os.path.join(data_dir, \"val\")\n",
    "print(os.path.exists(train_dir), os.path.exists(val_dir))\n",
    "\n",
    "# origin_train_list = [img for img in glob.glob(train_dir + \"/*/*\") if os.path.isfile(img)]\n",
    "# origin_val_list = [img for img in glob.glob(val_dir + \"/*/*\") if os.path.isfile(img)]\n",
    "origin_train_list = glob.glob(train_dir + \"/*/*\")\n",
    "origin_val_list = glob.glob(val_dir + \"/*/*\")\n",
    "train_list = origin_train_list[:]\n",
    "val_list = origin_val_list[:]\n",
    "random.shuffle(train_list)\n",
    "random.shuffle(val_list)\n",
    "print(f\"train: {len(train_list)}, val: {len(val_list)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcd50155",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T13:22:56.945906Z",
     "iopub.status.busy": "2025-06-10T13:22:56.945479Z",
     "iopub.status.idle": "2025-06-10T13:22:56.950649Z",
     "shell.execute_reply": "2025-06-10T13:22:56.949908Z",
     "shell.execute_reply.started": "2025-06-10T13:22:56.945889Z"
    },
    "papermill": {
     "duration": 0.008916,
     "end_time": "2025-06-09T11:09:47.999126",
     "exception": false,
     "start_time": "2025-06-09T11:09:47.990210",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# function to process data: gray_100x100_norm\n",
    "# DO NOT CHANGE IN THE SAME DATA VERSION\n",
    "import torchvision.transforms.v2 as T\n",
    "transform = transforms.v2.Compose([\n",
    "    T.ToImage(),\n",
    "    T.Grayscale(num_output_channels=1),\n",
    "    T.Resize((100, 100)),\n",
    "    T.ToDtype(torch.float32, scale=True),\n",
    "    T.Normalize(mean=[0.5], std=[0.5]),  # CÃ¢n chá»‰nh láº¡i náº¿u báº¡n cÃ³ thá»‘ng kÃª cá»¥ thá»ƒ hÆ¡n\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9e65958",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T13:22:56.951772Z",
     "iopub.status.busy": "2025-06-10T13:22:56.951500Z",
     "iopub.status.idle": "2025-06-10T13:22:56.988608Z",
     "shell.execute_reply": "2025-06-10T13:22:56.987744Z",
     "shell.execute_reply.started": "2025-06-10T13:22:56.951747Z"
    },
    "papermill": {
     "duration": 0.015691,
     "end_time": "2025-06-09T11:09:48.018175",
     "exception": false,
     "start_time": "2025-06-09T11:09:48.002484",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pyheif\n",
    "import torch\n",
    "\n",
    "\n",
    "def convert_heic_to_jpeg(heic_path, jpeg_path):\n",
    "    try:\n",
    "        heif_file = pyheif.read(heic_path)\n",
    "        image = Image.frombytes(\n",
    "            heif_file.mode, \n",
    "            heif_file.size, \n",
    "            heif_file.data, \n",
    "            \"raw\", \n",
    "            heif_file.mode, \n",
    "            heif_file.stride,\n",
    "        )\n",
    "        image.save(jpeg_path, format=\"JPEG\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\tðŸ›‘ Lá»—i chuyá»ƒn Ä‘á»•i .heic: {heic_path} â€” {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8375af7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T13:22:56.989966Z",
     "iopub.status.busy": "2025-06-10T13:22:56.989708Z",
     "iopub.status.idle": "2025-06-10T13:22:56.999024Z",
     "shell.execute_reply": "2025-06-10T13:22:56.998155Z",
     "shell.execute_reply.started": "2025-06-10T13:22:56.989944Z"
    },
    "papermill": {
     "duration": 0.012383,
     "end_time": "2025-06-09T11:09:48.033845",
     "exception": false,
     "start_time": "2025-06-09T11:09:48.021462",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "\n",
    "\n",
    "def read_heic(img_path):\n",
    "    jpeg_path = \"heic2jpeg/\" + img_path.split(\"/\")[-1].replace(\".HEIC\", \".jpeg\")\n",
    "    convert_heic_to_jpeg(img_path, jpeg_path)\n",
    "    image = read_image(jpeg_path, mode=\"RGB\")\n",
    "    if image is not None:\n",
    "        print(\"--> Converted to JPEG\")\n",
    "    else:\n",
    "        print(\"--> Can't convert to JPEG\")\n",
    "    return image\n",
    "    \n",
    "\n",
    "class custom_image_dataset(torch.utils.data.IterableDataset):\n",
    "    def __init__(self, image_lists, transform=None, test=False):\n",
    "        # self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.image_lists = image_lists\n",
    "        self.transform = transform\n",
    "        self.test = test\n",
    "\n",
    "    def __read_image(self, img_path):\n",
    "        try:\n",
    "          if img_path.endswith(\".HEIC\"):\n",
    "              print(\"\\nFound heic\")\n",
    "              image = read_heic(img_path)\n",
    "          else:\n",
    "              image = read_image(img_path, mode=\"RGB\")\n",
    "          truth = -1\n",
    "          if not self.test:\n",
    "              label_str = os.path.basename(img_path).split(\"_\")[1]  \n",
    "              truth = torch.tensor(int(label_str))\n",
    "          if self.transform:\n",
    "              image = self.transform(image)\n",
    "          return image, truth, img_path # Path sáº½ ráº¥t cáº§n Ä‘á»ƒ debug\n",
    "        except Exception as e:\n",
    "          print(f\"**Error reading custom_image_dataset: {e}\")\n",
    "          return None\n",
    "\n",
    "    def __iter__(self):\n",
    "        worker_info = torch.utils.data.get_worker_info()\n",
    "        if worker_info is None:  # single-process data loading, return the full iterator\n",
    "            iter_start = 0\n",
    "            iter_end = len(self.image_lists)\n",
    "        else:  # in a worker process\n",
    "            # split workload\n",
    "            per_worker = int(len(self.image_lists) / float(worker_info.num_workers))\n",
    "            worker_id = worker_info.id\n",
    "            iter_start =  worker_id * per_worker\n",
    "            iter_end = min(iter_start + per_worker, len(self.image_lists))\n",
    "        return iter(\n",
    "            filter(lambda x : x is not None\n",
    "                  , map(self.__read_image, self.image_lists[iter_start : iter_end] )\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_lists)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c93fdc60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T13:22:57.000887Z",
     "iopub.status.busy": "2025-06-10T13:22:57.000606Z",
     "iopub.status.idle": "2025-06-10T13:22:57.022270Z",
     "shell.execute_reply": "2025-06-10T13:22:57.021596Z",
     "shell.execute_reply.started": "2025-06-10T13:22:57.000864Z"
    },
    "papermill": {
     "duration": 0.00856,
     "end_time": "2025-06-09T11:09:48.045739",
     "exception": false,
     "start_time": "2025-06-09T11:09:48.037179",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"heic2jpeg\"):\n",
    "    os.makedirs(\"heic2jpeg\")\n",
    "else:\n",
    "    shutil.rmtree(\"heic2jpeg\")\n",
    "    print(\"deleted old folder 'heic2jpeg'\")\n",
    "    os.makedirs(\"heic2jpeg\")\n",
    "    print(\"Created new 'heic2jpeg'\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f99c99d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T13:22:57.023262Z",
     "iopub.status.busy": "2025-06-10T13:22:57.023018Z",
     "iopub.status.idle": "2025-06-10T13:22:57.139532Z",
     "shell.execute_reply": "2025-06-10T13:22:57.138496Z",
     "shell.execute_reply.started": "2025-06-10T13:22:57.023241Z"
    },
    "papermill": {
     "duration": 0.29075,
     "end_time": "2025-06-09T11:09:48.339873",
     "exception": false,
     "start_time": "2025-06-09T11:09:48.049123",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 2\n",
      "/kaggle/input/handwritten-tl/digits_data/train/2/train_2_2_05_0377.jpg\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=100x100>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp = custom_image_dataset(train_list[:10], transform=transform)\n",
    "it = iter(temp)\n",
    "img, truth, path = next(it)\n",
    "\n",
    "print(f\"label: {truth}\")\n",
    "print(path)\n",
    "\n",
    "display(to_pil_image(img))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "380dd3ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T13:22:57.140455Z",
     "iopub.status.busy": "2025-06-10T13:22:57.140230Z",
     "iopub.status.idle": "2025-06-10T13:22:57.148742Z",
     "shell.execute_reply": "2025-06-10T13:22:57.148068Z",
     "shell.execute_reply.started": "2025-06-10T13:22:57.140437Z"
    },
    "papermill": {
     "duration": 0.011983,
     "end_time": "2025-06-09T11:09:48.355605",
     "exception": false,
     "start_time": "2025-06-09T11:09:48.343622",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num workers: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "num_workers = os.cpu_count()\n",
    "print(f\"Num workers: {num_workers}\")\n",
    "trainset = custom_image_dataset(train_list,transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, num_workers=num_workers)\n",
    "\n",
    "valset = custom_image_dataset(val_list, transform=transform)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=BATCH_SIZE, num_workers=num_workers)\n",
    "\n",
    "classes = [i for i in range(10)]\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2508736b",
   "metadata": {
    "papermill": {
     "duration": 0.00342,
     "end_time": "2025-06-09T11:09:48.362614",
     "exception": false,
     "start_time": "2025-06-09T11:09:48.359194",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Model config**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68c38cb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T13:22:57.150492Z",
     "iopub.status.busy": "2025-06-10T13:22:57.150244Z",
     "iopub.status.idle": "2025-06-10T13:22:57.181609Z",
     "shell.execute_reply": "2025-06-10T13:22:57.180948Z",
     "shell.execute_reply.started": "2025-06-10T13:22:57.150466Z"
    },
    "papermill": {
     "duration": 0.021532,
     "end_time": "2025-06-09T11:09:48.387662",
     "exception": false,
     "start_time": "2025-06-09T11:09:48.366130",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5) # in_chanels, out_chanels, kernel size \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(7744, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(f\"input: {x.shape}\")\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        # print(f\"after conv2d and pooling: {x.shape}\")\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # print(f\"after conv2d_2 and pooling: {x.shape}\")\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        # print(f\"after flatten: {x.shape}\")\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # print(f\"after fc1: {x.shape}\")\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # print(f\"after fc2: {x.shape}\")\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58cb277a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T13:22:57.182773Z",
     "iopub.status.busy": "2025-06-10T13:22:57.182566Z",
     "iopub.status.idle": "2025-06-10T13:22:57.191358Z",
     "shell.execute_reply": "2025-06-10T13:22:57.190450Z",
     "shell.execute_reply.started": "2025-06-10T13:22:57.182757Z"
    },
    "papermill": {
     "duration": 0.014385,
     "end_time": "2025-06-09T11:09:48.405565",
     "exception": false,
     "start_time": "2025-06-09T11:09:48.391180",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "from contextlib import redirect_stdout\n",
    "\n",
    "# Ghi cáº£ ra file vÃ  mÃ n hÃ¬nh\n",
    "class DualWriter:\n",
    "    def __init__(self, file):\n",
    "        self.file = file\n",
    "        self.stdout = sys.__stdout__  # console tháº­t\n",
    "\n",
    "    def write(self, text):\n",
    "        self.stdout.write(text)\n",
    "        self.file.write(text)\n",
    "\n",
    "    def flush(self):\n",
    "        self.stdout.flush()\n",
    "        self.file.flush()\n",
    "\n",
    "class SaveBestModel:\n",
    "    def __init__(self, save_path=\"best_model.pth\", mode='min'):\n",
    "        self.best_value = float('inf') if mode == 'min' else -float('inf')\n",
    "        self.save_path = save_path\n",
    "        self.mode = mode\n",
    "\n",
    "    def __call__(self, current_value, model):\n",
    "        is_better = current_value < self.best_value if self.mode == 'min' else current_value > self.best_value\n",
    "        if is_better:\n",
    "            self.best_value = current_value\n",
    "            torch.save(model.state_dict(), self.save_path)\n",
    "            print(f\"âœ… Saved new best model ({self.mode} = {current_value:.4f})\")\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, mode='min'):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_value = float('inf') if mode == 'min' else -float('inf')\n",
    "        self.early_stop = False\n",
    "        self.mode = mode\n",
    "\n",
    "    def __call__(self, current_value):\n",
    "        is_better = current_value < self.best_value if self.mode == 'min' else current_value > self.best_value\n",
    "\n",
    "        if is_better:\n",
    "            self.best_value = current_value\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            print(f\"âš ï¸ No improvement. EarlyStopping counter: {self.counter}/{self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0f8b4f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T13:22:57.192468Z",
     "iopub.status.busy": "2025-06-10T13:22:57.192185Z",
     "iopub.status.idle": "2025-06-10T13:23:05.945695Z",
     "shell.execute_reply": "2025-06-10T13:23:05.944486Z",
     "shell.execute_reply.started": "2025-06-10T13:22:57.192442Z"
    },
    "papermill": {
     "duration": 2382.731854,
     "end_time": "2025-06-09T11:49:31.140982",
     "exception": false,
     "start_time": "2025-06-09T11:09:48.409128",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/20 [00:08<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_35/165253596.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mepoch_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1459\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1419\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1421\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "# Ghi log ra log.txt\n",
    "log_file = open(\"train_log.txt\", \"a\")  # má»Ÿ log file\n",
    "dual_output = DualWriter(log_file)\n",
    "save_best_model = SaveBestModel(\"best_model.pth\", mode='min')\n",
    "early_stopping = EarlyStopping(patience=5, mode='min')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using: {device}\")\n",
    "net.to(device)\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "with redirect_stdout(dual_output):\n",
    "    for epoch in tqdm(range(20), desc=\"Epochs: \"):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        print()\n",
    "        epoch_start = time.time()\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels, _ = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # print(inputs.device, labels.device, next(net.parameters()).device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        epoch_loss = running_loss / len(trainloader)\n",
    "        print(f\"Epoch {epoch+1} loss: {epoch_loss:.4f} - time: {time.time() - epoch_start}s\")\n",
    "\n",
    "        # Gá»i callback\n",
    "        save_best_model(epoch_loss, net)\n",
    "        early_stopping(epoch_loss)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print(\"â›” Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print(f'Finished Training in: {total_time}s')\n",
    "    \n",
    "print(\"ðŸŸ¢ ÄÃ£ ra khá»i with, chá»‰ in ra console, khÃ´ng ghi file\")\n",
    "log_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c30980b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T13:24:33.389748Z",
     "iopub.status.busy": "2025-06-10T13:24:33.389001Z",
     "iopub.status.idle": "2025-06-10T13:25:06.945701Z",
     "shell.execute_reply": "2025-06-10T13:25:06.944849Z",
     "shell.execute_reply.started": "2025-06-10T13:24:33.389706Z"
    },
    "papermill": {
     "duration": 31.412307,
     "end_time": "2025-06-09T11:50:02.558804",
     "exception": false,
     "start_time": "2025-06-09T11:49:31.146497",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 62.28 %\n"
     ]
    }
   ],
   "source": [
    "#validate\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Net()\n",
    "model.load_state_dict(torch.load('/kaggle/input/cnn2layers_config/pytorch/default/1/best_model.pth', map_location=device))\n",
    "model.to(device)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in valloader:\n",
    "        images, labels,_ = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy of the network on the test images: {accuracy:.2f} %')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b06fa39",
   "metadata": {
    "papermill": {
     "duration": 0.005256,
     "end_time": "2025-06-09T11:50:02.569696",
     "exception": false,
     "start_time": "2025-06-09T11:50:02.564440",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **PREDICT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06307e7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T13:28:19.256048Z",
     "iopub.status.busy": "2025-06-10T13:28:19.255327Z",
     "iopub.status.idle": "2025-06-10T13:29:04.231899Z",
     "shell.execute_reply": "2025-06-10T13:29:04.231110Z",
     "shell.execute_reply.started": "2025-06-10T13:28:19.256018Z"
    },
    "papermill": {
     "duration": 40.875105,
     "end_time": "2025-06-09T11:50:43.450205",
     "exception": false,
     "start_time": "2025-06-09T11:50:02.575100",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: 2939\n",
      "\n",
      "Found heic\n",
      "\n",
      "Found heic\n",
      "--> Converted to JPEG\n",
      "--> Converted to JPEG\n",
      "**Error reading custom_image_dataset: Unsupported image file. Only jpeg, png, webp and gif are currently supported. For avif and heic format, please rely on `decode_avif` and `decode_heic` directly.\n",
      "\n",
      "Found heic\n",
      "\n",
      "Found heic\n",
      "\n",
      "Found heic\n",
      "--> Converted to JPEG\n",
      "--> Converted to JPEG\n",
      "--> Converted to JPEG\n",
      "**Error reading custom_image_dataset: Unsupported image file. Only jpeg, png, webp and gif are currently supported. For avif and heic format, please rely on `decode_avif` and `decode_heic` directly.\n",
      "\n",
      "Found heic\n",
      "--> Converted to JPEG\n",
      "**Error reading custom_image_dataset: Unsupported image file. Only jpeg, png, webp and gif are currently supported. For avif and heic format, please rely on `decode_avif` and `decode_heic` directly.\n",
      "\n",
      "Found heic\n",
      "--> Converted to JPEG\n",
      "\n",
      "Found heic\n",
      "--> Converted to JPEG\n",
      "\n",
      "Found heic\n",
      "**Error reading custom_image_dataset: Unsupported image file. Only jpeg, png, webp and gif are currently supported. For avif and heic format, please rely on `decode_avif` and `decode_heic` directly.\n",
      "--> Converted to JPEG\n",
      "\n",
      "Found heic\n",
      "--> Converted to JPEG\n",
      "\n",
      "Found heic\n",
      "**Error reading custom_image_dataset: Unsupported image file. Only jpeg, png, webp and gif are currently supported. For avif and heic format, please rely on `decode_avif` and `decode_heic` directly.\n",
      "\n",
      "Found heic\n",
      "--> Converted to JPEG\n",
      "\n",
      "Found heic\n",
      "\n",
      "Found heic\n",
      "--> Converted to JPEG\n",
      "**Error reading custom_image_dataset: Unsupported image file. Only jpeg, png, webp and gif are currently supported. For avif and heic format, please rely on `decode_avif` and `decode_heic` directly.\n",
      "--> Converted to JPEG\n",
      "--> Converted to JPEG\n",
      "**Error reading custom_image_dataset: Unsupported image file. Only jpeg, png, webp and gif are currently supported. For avif and heic format, please rely on `decode_avif` and `decode_heic` directly.\n",
      "\n",
      "Found heic\n",
      "\n",
      "Found heic\n",
      "--> Converted to JPEG\n",
      "--> Converted to JPEG\n",
      "\n",
      "Found heic\n",
      "**Error reading custom_image_dataset: Unsupported image file. Only jpeg, png, webp and gif are currently supported. For avif and heic format, please rely on `decode_avif` and `decode_heic` directly.\n",
      "--> Converted to JPEG\n",
      "\n",
      "Found heic\n",
      "--> Converted to JPEG\n",
      "**Error reading custom_image_dataset: Unsupported image file. Only jpeg, png, webp and gif are currently supported. For avif and heic format, please rely on `decode_avif` and `decode_heic` directly.\n",
      "\n",
      "Found heic\n",
      "--> Converted to JPEG\n",
      "**Error reading custom_image_dataset: Unsupported image file. Only jpeg, png, webp and gif are currently supported. For avif and heic format, please rely on `decode_avif` and `decode_heic` directly.\n",
      "\n",
      "Found heic\n",
      "--> Converted to JPEG\n",
      "\n",
      "Found heic\n",
      "--> Converted to JPEG\n",
      "\n",
      "Found heic\n",
      "\n",
      "Found heic\n",
      "--> Converted to JPEG\n",
      "--> Converted to JPEG\n",
      "\n",
      "Found heic\n",
      "--> Converted to JPEG\n",
      "\n",
      "Found heic\n",
      "--> Converted to JPEG\n",
      "\n",
      "Found heic\n",
      "\n",
      "Found heic\n",
      "--> Converted to JPEG\n",
      "**Error reading custom_image_dataset: Unsupported image file. Only jpeg, png, webp and gif are currently supported. For avif and heic format, please rely on `decode_avif` and `decode_heic` directly.\n",
      "--> Converted to JPEG\n",
      "\n",
      "Found heic\n",
      "--> Converted to JPEG\n",
      "\n",
      "Found heic\n",
      "--> Converted to JPEG\n",
      "\n",
      "Found heic\n",
      "--> Converted to JPEG\n",
      "Predictions saved in 'predict_2k.txt'\n"
     ]
    }
   ],
   "source": [
    "# PREDICT\n",
    "test_dir = \"/kaggle/input/handwritten-test-cs114\"\n",
    "test_list = [os.path.join(test_dir, img) for img in os.listdir(test_dir)]\n",
    "print(f\"samples: {len(test_list)}\")\n",
    "testset = custom_image_dataset(test_list, transform=transform, test=True)\n",
    "testloader = torch.utils.data.DataLoader(testset,batch_size=BATCH_SIZE, num_workers=num_workers)\n",
    "\n",
    "predict_txt = \"\"\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels, paths = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # save\n",
    "        for path, pred in zip(paths, predicted):\n",
    "            path = path.replace(test_dir, \"\").lstrip(os.sep)  # Strip test_dir and leading separator\n",
    "            predict_txt += f\"{path},{pred.item()}\\n\"\n",
    "\n",
    "# Write to file in text mode\n",
    "with open(\"/kaggle/working/predict_2k.txt\", \"w\") as file:\n",
    "    file.write(predict_txt)\n",
    "print(\"Predictions saved in 'predict_2k.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bfc6b48e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T13:29:04.233521Z",
     "iopub.status.busy": "2025-06-10T13:29:04.233284Z",
     "iopub.status.idle": "2025-06-10T13:29:04.323970Z",
     "shell.execute_reply": "2025-06-10T13:29:04.323177Z",
     "shell.execute_reply.started": "2025-06-10T13:29:04.233499Z"
    },
    "papermill": {
     "duration": 0.099775,
     "end_time": "2025-06-09T11:50:43.561461",
     "exception": false,
     "start_time": "2025-06-09T11:50:43.461686",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: -1\n",
      "/kaggle/input/handwritten-test-cs114/389269258327f495063eeb7863aeb323  -.jpg\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=100x100>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp = custom_image_dataset(test_list[:10], transform=transform, test=True)\n",
    "it = iter(temp)\n",
    "img, truth, path = next(it)\n",
    "\n",
    "\n",
    "print(f\"label: {truth}\")\n",
    "print(path)\n",
    "\n",
    "display(to_pil_image(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8f245d-58a5-4c96-9870-9335f1f326f7",
   "metadata": {},
   "source": [
    "# **PREDICT 10K**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37597590-d85d-4112-a070-3ee3d818ca8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T13:29:04.324962Z",
     "iopub.status.busy": "2025-06-10T13:29:04.324741Z",
     "iopub.status.idle": "2025-06-10T13:32:17.013622Z",
     "shell.execute_reply": "2025-06-10T13:32:17.012462Z",
     "shell.execute_reply.started": "2025-06-10T13:29:04.324941Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: 9974\n",
      "Predictions saved in 'predict_10k.txt'\n"
     ]
    }
   ],
   "source": [
    "# PREDICT\n",
    "test_dir = \"/kaggle/input/handwritten-test-10k\"\n",
    "test_list = [os.path.join(test_dir, img) for img in os.listdir(test_dir)]\n",
    "print(f\"samples: {len(test_list)}\")\n",
    "testset = custom_image_dataset(test_list, transform=transform, test=True)\n",
    "testloader = torch.utils.data.DataLoader(testset,batch_size=BATCH_SIZE, num_workers=num_workers)\n",
    "\n",
    "predict_txt = \"\"\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels, paths = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # save\n",
    "        for path, pred in zip(paths, predicted):\n",
    "            path = path.replace(test_dir, \"\").lstrip(os.sep)  # Strip test_dir and leading separator\n",
    "            predict_txt += f\"{path},{pred.item()}\\n\"\n",
    "\n",
    "# Write to file in text mode\n",
    "with open(\"/kaggle/working/predict_10k.txt\", \"w\") as file:\n",
    "    file.write(predict_txt)\n",
    "print(\"Predictions saved in 'predict_10k.txt'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1edb94b",
   "metadata": {
    "papermill": {
     "duration": 0.01206,
     "end_time": "2025-06-09T11:50:43.606884",
     "exception": false,
     "start_time": "2025-06-09T11:50:43.594824",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Save**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dd9456",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-10T13:23:05.951366Z",
     "iopub.status.idle": "2025-06-10T13:23:05.951665Z",
     "shell.execute_reply": "2025-06-10T13:23:05.951564Z",
     "shell.execute_reply.started": "2025-06-10T13:23:05.951551Z"
    },
    "papermill": {
     "duration": 0.017689,
     "end_time": "2025-06-09T11:50:43.635500",
     "exception": false,
     "start_time": "2025-06-09T11:50:43.617811",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "log_path = \"train_log.txt\"\n",
    "with open(log_path, \"a\") as f:\n",
    "    f.write(\"\\n\\n\" + \"=\"*60 + \"\\n\")\n",
    "    f.write(\"Training Summary\\n\")\n",
    "    f.write(\"=\"*60 + \"\\n\")\n",
    "    f.write(f\"Time: {total_time//60:.0f}m {total_time%60:.0f}s\\n\")\n",
    "    f.write(f\"Best Validation Accuracy: {accuracy:.4f}\\n\")\n",
    "    f.write(f\"\\nOptimizer: {optimizer.__class__.__name__} - {optimizer.state_dict()['param_groups'][0]}\\n\")\n",
    "    f.write(f\"Loss Function: {criterion.__class__.__name__}\\n\")\n",
    "    f.write(\"=\"*60 + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca936443",
   "metadata": {
    "papermill": {
     "duration": 0.011311,
     "end_time": "2025-06-09T11:50:43.657703",
     "exception": false,
     "start_time": "2025-06-09T11:50:43.646392",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **TEST**"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7608653,
     "sourceId": 12086766,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7613469,
     "sourceId": 12094235,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7614858,
     "sourceId": 12096088,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 372611,
     "modelInstanceId": 351363,
     "sourceId": 431041,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2475.969652,
   "end_time": "2025-06-09T11:50:46.658274",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-09T11:09:30.688622",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
